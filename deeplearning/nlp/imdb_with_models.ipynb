{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1mDownloading and preparing dataset Unknown size (download: Unknown size, generated: Unknown size, total: Unknown size) to C:\\Users\\Jihoo\\tensorflow_datasets\\imdb_reviews\\plain_text\\1.0.0...\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Dl Completed...', max=1.0, style=Progre…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7148dba281d942e3bc89346e70880f24"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Dl Size...', max=1.0, style=ProgressSty…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "273668613a6e4fb594182abf2a5a3d2a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, description='Generating splits...', max=3.0, style=ProgressStyle(descr…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "402b9020e816495fa46041cccca9d4c5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Generating train examples...', max=1.0,…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bc9f08bda06241f4b3060c23116d5893"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, description='Shuffling C:\\\\Users\\\\Jihoo\\\\tensorflow_datasets\\\\imdb_rev…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3553915f8e1148f0973721de84a011ab"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Generating test examples...', max=1.0, …",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "643b4318b5134524a51fab63d5185f5b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, description='Shuffling C:\\\\Users\\\\Jihoo\\\\tensorflow_datasets\\\\imdb_rev…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3959184796d548028955ad28f05b8cd0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Generating unsupervised examples...', m…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2528c460b43a47079222ef86abe08766"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, description='Shuffling C:\\\\Users\\\\Jihoo\\\\tensorflow_datasets\\\\imdb_rev…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "311be1921fed49ecae0c9ec7e08fdd55"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1mDataset imdb_reviews downloaded and prepared to C:\\Users\\Jihoo\\tensorflow_datasets\\imdb_reviews\\plain_text\\1.0.0. Subsequent calls will reuse this data.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "# Download the plain text dataset\n",
    "imdb, info = tfds.load('imdb_reviews', with_info=True, as_supervised=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "training_data, test_data = imdb['train'], imdb['test']\n",
    "\n",
    "training_sentences = []\n",
    "training_labels = []\n",
    "\n",
    "testing_sentences = []\n",
    "testing_labels = []\n",
    "\n",
    "for s, l in training_data:\n",
    "    training_sentences.append(s.numpy().decode('utf8'))\n",
    "    training_labels.append(l.numpy())\n",
    "\n",
    "for s, l in test_data:\n",
    "    testing_sentences.append(s.numpy().decode('utf8'))\n",
    "    testing_labels.append(l.numpy())\n",
    "\n",
    "training_labels_final = np.array(training_labels)\n",
    "testing_labels_final = np.array(testing_labels)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "vocab_size = 10000\n",
    "max_length = 120\n",
    "trunc_type = 'post'\n",
    "oov_tok = \"<OOV>\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words = vocab_size, oov_token=oov_tok)\n",
    "\n",
    "tokenizer.fit_on_texts(training_sentences)\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(training_sentences)\n",
    "padded = pad_sequences(sequences,maxlen=max_length, truncating=trunc_type)\n",
    "\n",
    "testing_sequences = tokenizer.texts_to_sequences(testing_sentences)\n",
    "testing_padded = pad_sequences(testing_sequences, maxlen=max_length)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Model 1. Flatten"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 120, 16)           160000    \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 1920)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 6)                 11526     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 7         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 171,533\n",
      "Trainable params: 171,533\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "196/196 [==============================] - 3s 8ms/step - loss: 0.6266 - accuracy: 0.6342 - val_loss: 0.4124 - val_accuracy: 0.8250\n",
      "Epoch 2/10\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.3289 - accuracy: 0.8643 - val_loss: 0.3338 - val_accuracy: 0.8544\n",
      "Epoch 3/10\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.2066 - accuracy: 0.9270 - val_loss: 0.3518 - val_accuracy: 0.8477\n",
      "Epoch 4/10\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.1172 - accuracy: 0.9688 - val_loss: 0.3980 - val_accuracy: 0.8375\n",
      "Epoch 5/10\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.0534 - accuracy: 0.9924 - val_loss: 0.4559 - val_accuracy: 0.8305\n",
      "Epoch 6/10\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.0233 - accuracy: 0.9984 - val_loss: 0.4849 - val_accuracy: 0.8325\n",
      "Epoch 7/10\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.0116 - accuracy: 0.9996 - val_loss: 0.5235 - val_accuracy: 0.8311\n",
      "Epoch 8/10\n",
      "196/196 [==============================] - 1s 8ms/step - loss: 0.0063 - accuracy: 0.9999 - val_loss: 0.5522 - val_accuracy: 0.8313\n",
      "Epoch 9/10\n",
      "196/196 [==============================] - 1s 7ms/step - loss: 0.0041 - accuracy: 0.9999 - val_loss: 0.5761 - val_accuracy: 0.8318\n",
      "Epoch 10/10\n",
      "196/196 [==============================] - 2s 8ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.5998 - val_accuracy: 0.8308\n"
     ]
    }
   ],
   "source": [
    "embedding_dim = 16\n",
    "dense_dim = 6\n",
    "NUM_EPOCHS = 10\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "model_flatten = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(dense_dim, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model_flatten.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.Adam(), metrics=['accuracy'])\n",
    "\n",
    "model_flatten.summary()\n",
    "\n",
    "history_flatten = model_flatten.fit(padded, training_labels_final, batch_size=BATCH_SIZE, epochs=NUM_EPOCHS, validation_data=(testing_padded, testing_labels_final))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (None, 120, 16)           160000    \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 64)               12544     \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 6)                 390       \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 7         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 172,941\n",
      "Trainable params: 172,941\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "196/196 [==============================] - 31s 129ms/step - loss: 0.5512 - accuracy: 0.6986 - val_loss: 0.3921 - val_accuracy: 0.8320\n",
      "Epoch 2/10\n",
      "196/196 [==============================] - 22s 114ms/step - loss: 0.3227 - accuracy: 0.8690 - val_loss: 0.3657 - val_accuracy: 0.8363\n",
      "Epoch 3/10\n",
      "196/196 [==============================] - 24s 123ms/step - loss: 0.2530 - accuracy: 0.9036 - val_loss: 0.3605 - val_accuracy: 0.8452\n",
      "Epoch 4/10\n",
      "196/196 [==============================] - 22s 113ms/step - loss: 0.2132 - accuracy: 0.9210 - val_loss: 0.4082 - val_accuracy: 0.8378\n",
      "Epoch 5/10\n",
      "196/196 [==============================] - 23s 118ms/step - loss: 0.1818 - accuracy: 0.9354 - val_loss: 0.4276 - val_accuracy: 0.8329\n",
      "Epoch 6/10\n",
      "196/196 [==============================] - 22s 114ms/step - loss: 0.1576 - accuracy: 0.9459 - val_loss: 0.5320 - val_accuracy: 0.8266\n",
      "Epoch 7/10\n",
      "196/196 [==============================] - 21s 105ms/step - loss: 0.1331 - accuracy: 0.9563 - val_loss: 0.4912 - val_accuracy: 0.8234\n",
      "Epoch 8/10\n",
      "196/196 [==============================] - 21s 110ms/step - loss: 0.1178 - accuracy: 0.9618 - val_loss: 0.5476 - val_accuracy: 0.8167\n",
      "Epoch 9/10\n",
      "196/196 [==============================] - 22s 112ms/step - loss: 0.1062 - accuracy: 0.9673 - val_loss: 0.5044 - val_accuracy: 0.8165\n",
      "Epoch 10/10\n",
      "196/196 [==============================] - 22s 114ms/step - loss: 0.0844 - accuracy: 0.9749 - val_loss: 0.6531 - val_accuracy: 0.8204\n"
     ]
    }
   ],
   "source": [
    "embedding_dim = 16\n",
    "dense_dim = 6\n",
    "lstm_dim = 32\n",
    "NUM_EPOCHS = 10\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "model_lstm = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(lstm_dim)),\n",
    "    tf.keras.layers.Dense(dense_dim, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model_lstm.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.Adam(), metrics=['accuracy'])\n",
    "\n",
    "model_lstm.summary()\n",
    "\n",
    "history_lstm = model_lstm.fit(padded, training_labels_final, batch_size=BATCH_SIZE, epochs=NUM_EPOCHS, validation_data=(testing_padded, testing_labels_final))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_3 (Embedding)     (None, 120, 16)           160000    \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirectio  (None, 64)               9600      \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 6)                 390       \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 7         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 169,997\n",
      "Trainable params: 169,997\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "196/196 [==============================] - 27s 109ms/step - loss: 0.5957 - accuracy: 0.6426 - val_loss: 0.4091 - val_accuracy: 0.8152\n",
      "Epoch 2/10\n",
      "196/196 [==============================] - 19s 96ms/step - loss: 0.3256 - accuracy: 0.8648 - val_loss: 0.3404 - val_accuracy: 0.8540\n",
      "Epoch 3/10\n",
      "196/196 [==============================] - 18s 92ms/step - loss: 0.2398 - accuracy: 0.9076 - val_loss: 0.3652 - val_accuracy: 0.8479\n",
      "Epoch 4/10\n",
      "196/196 [==============================] - 17s 85ms/step - loss: 0.1912 - accuracy: 0.9300 - val_loss: 0.4269 - val_accuracy: 0.8341\n",
      "Epoch 5/10\n",
      "196/196 [==============================] - 20s 103ms/step - loss: 0.1487 - accuracy: 0.9478 - val_loss: 0.4797 - val_accuracy: 0.8280\n",
      "Epoch 6/10\n",
      "196/196 [==============================] - 20s 103ms/step - loss: 0.1183 - accuracy: 0.9590 - val_loss: 0.5593 - val_accuracy: 0.8266\n",
      "Epoch 7/10\n",
      "196/196 [==============================] - 19s 95ms/step - loss: 0.1069 - accuracy: 0.9619 - val_loss: 0.7074 - val_accuracy: 0.8002\n",
      "Epoch 8/10\n",
      "196/196 [==============================] - 18s 90ms/step - loss: 0.0874 - accuracy: 0.9706 - val_loss: 0.6423 - val_accuracy: 0.8215\n",
      "Epoch 9/10\n",
      "196/196 [==============================] - 18s 92ms/step - loss: 0.0672 - accuracy: 0.9787 - val_loss: 0.7393 - val_accuracy: 0.8176\n",
      "Epoch 10/10\n",
      "196/196 [==============================] - 17s 87ms/step - loss: 0.0528 - accuracy: 0.9836 - val_loss: 0.7953 - val_accuracy: 0.8132\n"
     ]
    }
   ],
   "source": [
    "embedding_dim = 16\n",
    "dense_dim = 6\n",
    "gru_dim = 32\n",
    "NUM_EPOCHS = 10\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "model_gru = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.GRU(gru_dim)),\n",
    "    tf.keras.layers.Dense(dense_dim, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model_gru.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.Adam(), metrics=['accuracy'])\n",
    "\n",
    "model_gru.summary()\n",
    "\n",
    "history_gru = model_gru.fit(padded, training_labels_final, batch_size=BATCH_SIZE, epochs=NUM_EPOCHS, validation_data=(testing_padded, testing_labels_final))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}